{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0443c9f4",
   "metadata": {},
   "source": [
    "Welcome to our explainer!\n",
    "\n",
    "In this Jupyter Notebook file, you will find all code related to the final project for group XX in Social Graphs & Interactions. Please open the sections below to examine the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea85887",
   "metadata": {},
   "source": [
    "# Scraping section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87803e84",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3162df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6f068",
   "metadata": {},
   "source": [
    "## Function for scraping and storing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdaf302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_movie_data(tmdb_id, i, TMDB_API_KEY):\n",
    "    '''\n",
    "    Fetches movie review data from TMDB API given a tmdb_id\n",
    "    '''\n",
    "    # rate limit: 40 requests every 10 seconds\n",
    "    if i % 39 == 0:\n",
    "        time.sleep(0.25)\n",
    "\n",
    "    url = (\n",
    "        f\"https://api.themoviedb.org/3/movie/{tmdb_id}/reviews\"\n",
    "        f\"?api_key={TMDB_API_KEY}&language=en-US\"\n",
    "    )\n",
    "\n",
    "    data = requests.get(url).json()\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_to_csv(row, filename=\"ml-latest/reviews.csv\"):\n",
    "    '''\n",
    "    Appends a row to a csv file\n",
    "    '''\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "def get_last_row_movie(filename=\"ml-latest/reviews.csv\"):\n",
    "    '''\n",
    "    Returns the movieId of the last row in the csv file\n",
    "    '''\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        last_line = f.readlines()[-1]\n",
    "        return int(last_line.split(',')[0])\n",
    "\n",
    "\n",
    "def process_movie_data(data, TMDB_API_KEY, file_path=\"ml-latest/reviews.csv\"):\n",
    "    '''\n",
    "    Processes movie data fetched from TMDB API.\n",
    "    Only pulls movieId + reviews.\n",
    "    '''\n",
    "\n",
    "    # check if csv exists\n",
    "    if os.path.exists(file_path):\n",
    "        last_movie_id = get_last_row_movie(file_path)\n",
    "        print(f\"Resuming from movieId: {last_movie_id}\")\n",
    "\n",
    "    else:\n",
    "        last_movie_id = 0\n",
    "        # write header\n",
    "        with open(file_path, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"movieId\", \"reviews\"])\n",
    "        print(\"Creating new reviews.csv file\")\n",
    "\n",
    "    for i, (movieId, imdbId, tmdbId) in enumerate(data.itertuples(index=False)):\n",
    "\n",
    "        # skip already processed movies\n",
    "        if movieId <= last_movie_id:\n",
    "            continue\n",
    "\n",
    "        # skip NaN tmdb id\n",
    "        if pd.isna(tmdbId):\n",
    "            continue\n",
    "\n",
    "        tmdbId = int(tmdbId)\n",
    "\n",
    "        # get review data\n",
    "        review_data = fetch_movie_data(tmdbId, i, TMDB_API_KEY)\n",
    "\n",
    "        # extract reviews\n",
    "        reviews_raw = review_data.get(\"results\", [])\n",
    "        reviews_texts = []\n",
    "\n",
    "        for r in reviews_raw[:5]:  # take first 20 reviews only\n",
    "            content = r.get(\"content\", \"\")\n",
    "            content = content.replace(\"\\n\", \" \").replace(\",\", \"\").replace(\"'\", \"\")\n",
    "            reviews_texts.append(content)\n",
    "\n",
    "        reviews_joined = \"|\".join(reviews_texts)\n",
    "\n",
    "        # write to csv\n",
    "        row = [movieId, reviews_joined]\n",
    "        write_to_csv(row, file_path)\n",
    "\n",
    "        print(f\"Saved movieId {movieId}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMDB_API_KEY = \"be0552b72397e07ffaa4d7d488b22b92\"\n",
    "\n",
    "movies_df = pd.read_csv(\"data/links_action.csv\")\n",
    "process_movie_data(movies_df, TMDB_API_KEY=TMDB_API_KEY, file_path=\"data/reviews_final_one_AA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63372c3",
   "metadata": {},
   "source": [
    "# Graph section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8abb0f9",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145304f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7c05a",
   "metadata": {},
   "source": [
    "## Initialization of data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bebad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"data/overview.csv\")\n",
    "movies_df = pd.read_csv(\"data/movies.csv\")\n",
    "\n",
    "# Clean the cast column so it is ready for splitting\n",
    "df[\"cast_names\"] = df[\"cast_names\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Converting of casts into lists (orignally, they were seperated with the symbol |)\n",
    "df[\"cast_list\"] = df[\"cast_names\"].apply(\n",
    "    lambda s: [c.strip() for c in s.split(\"|\") if c.strip() != \"\"]\n",
    ")\n",
    "\n",
    "# Join overview with movies\n",
    "merged_df = df.merge(movies_df[[\"movieId\", \"genres\"]], on=\"movieId\", how=\"left\")\n",
    "\n",
    "# Split of genre to lists\n",
    "merged_df[\"genres\"] = merged_df[\"genres\"].fillna(\"\")\n",
    "merged_df[\"genre_list\"] = merged_df[\"genres\"].apply(\n",
    "    lambda s: [g.strip() for g in s.split(\"|\") if g.strip() != \"\"]\n",
    ")\n",
    "\n",
    "# Filtering the genre\n",
    "target_genre = \"Action\"\n",
    "genre_df = merged_df[merged_df[\"genre_list\"].apply(lambda lst: target_genre in lst) ].copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocknet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
