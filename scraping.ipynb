{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53795a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import re\n",
    "import time\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MovieLens data\n",
    "links = pd.read_csv('links.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "tags = pd.read_csv('tags.csv')\n",
    "genome_scores = pd.read_csv('genome-scores.csv')\n",
    "genome_tags = pd.read_csv('genome-tags.csv')\n",
    "\n",
    "filliste = [\n",
    "    (\"links\", links),\n",
    "    (\"movies\", movies),\n",
    "    (\"ratings\", ratings),\n",
    "    (\"tags\", tags),\n",
    "    (\"genome_scores\", genome_scores),\n",
    "    (\"genome_tags\", genome_tags)\n",
    "]\n",
    "\n",
    "# Make folders for caching\n",
    "os.makedirs(\"directors\", exist_ok=True)\n",
    "os.makedirs(\"actors\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66938f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_id_to_tt(imdb_id):\n",
    "    \"\"\"\n",
    "    Convert imdbId from links.csv (int or string) to proper tt-code, e.g. 114709 -> 'tt0114709'.\n",
    "    \"\"\"\n",
    "    s = str(imdb_id)\n",
    "    # ensure 7 digits\n",
    "    return f\"tt{s.zfill(7)}\"\n",
    "\n",
    "\n",
    "def fetch_imdb_html(tt_id, delay=0.5):\n",
    "    \"\"\"\n",
    "    Fetch HTML for a given tt-id from IMDB with a browser-like User-Agent.\n",
    "    delay: sleep to be nicer to the server (seconds).\n",
    "    \"\"\"\n",
    "    url = f\"https://www.imdb.com/title/{tt_id}/\"\n",
    "    req = urllib.request.Request(\n",
    "        url,\n",
    "        headers={\n",
    "            \"User-Agent\": (\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "            ),\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        }\n",
    "    )\n",
    "    with urllib.request.urlopen(req) as resp:\n",
    "        html = resp.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "    time.sleep(delay)\n",
    "    return html\n",
    "\n",
    "\n",
    "def parse_directors_actors_from_html(html):\n",
    "    \"\"\"\n",
    "    Use the <meta name=\"description\" ...> trick to get director(s) and actors.\n",
    "    Returns (directors, actors) as lists of strings.\n",
    "    \"\"\"\n",
    "    # Meta description\n",
    "    meta_match = re.search(\n",
    "        r'<meta name=\"description\" content=\"([^\"]+)\"',\n",
    "        html\n",
    "    )\n",
    "    if not meta_match:\n",
    "        return [], []\n",
    "\n",
    "    description = meta_match.group(1)\n",
    "\n",
    "    # Directors: 'Directed by ... .'\n",
    "    dir_match = re.search(r'Directed by (.*?)\\.', description)\n",
    "    directors = []\n",
    "    if dir_match:\n",
    "        directors_raw = dir_match.group(1)\n",
    "        directors = [d.strip() for d in re.split(r',| and ', directors_raw) if d.strip()]\n",
    "\n",
    "    # Actors: 'With ... .' (after the 'Directed by' sentence)\n",
    "    act_match = re.search(r'With (.*?)(?:\\.|;)', description)\n",
    "    actors = []\n",
    "    if act_match:\n",
    "        actors_raw = act_match.group(1)\n",
    "        actors = [a.strip() for a in re.split(r',| and ', actors_raw) if a.strip()]\n",
    "\n",
    "    return directors, actors\n",
    "\n",
    "\n",
    "def get_directors_actors_for_movie(movie_id, imdb_id, use_cache=True):\n",
    "    \"\"\"\n",
    "    High-level helper:\n",
    "    - if cached files exist in directors/actors, read them\n",
    "    - else scrape IMDB and write cache\n",
    "    Returns (directors, actors).\n",
    "    \"\"\"\n",
    "    dir_path = f\"directors/movie_{movie_id}_directors.txt\"\n",
    "    act_path = f\"actors/movie_{movie_id}_actors.txt\"\n",
    "\n",
    "    # Try cache first\n",
    "    if use_cache and os.path.exists(dir_path) and os.path.exists(act_path):\n",
    "        with open(dir_path, encoding=\"utf-8\") as f:\n",
    "            directors = [line.strip() for line in f if line.strip()]\n",
    "        with open(act_path, encoding=\"utf-8\") as f:\n",
    "            actors = [line.strip() for line in f if line.strip()]\n",
    "        return directors, actors\n",
    "\n",
    "    # Otherwise, scrape\n",
    "    tt_id = imdb_id_to_tt(imdb_id)\n",
    "    try:\n",
    "        html = fetch_imdb_html(tt_id)\n",
    "        directors, actors = parse_directors_actors_from_html(html)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch/parse for movieId {movie_id}, imdbId {imdb_id}: {e}\")\n",
    "        return [], []\n",
    "\n",
    "    # Save cache\n",
    "    with open(dir_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for d in directors:\n",
    "            f.write(d + \"\\n\")\n",
    "\n",
    "    with open(act_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for a in actors:\n",
    "            f.write(a + \"\\n\")\n",
    "\n",
    "    return directors, actors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2caf7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "movieId",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7daa5d5b-3294-4f5b-af9c-ffc852f15aa5",
       "rows": [
        [
         "1",
         "3.8935076093890357"
        ],
        [
         "2",
         "3.2781786884703235"
        ],
        [
         "3",
         "3.1712705436156763"
        ],
        [
         "4",
         "2.8683949801849407"
        ],
        [
         "5",
         "3.0769571546104677"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "movieId\n",
       "1    3.893508\n",
       "2    3.278179\n",
       "3    3.171271\n",
       "4    2.868395\n",
       "5    3.076957\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average rating for each movie\n",
    "movie_avg_rating = ratings.groupby(\"movieId\")[\"rating\"].mean()\n",
    "movie_avg_rating.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41fbdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch/parse for movieId 720, imdbId 118114: HTTP Error 404: Not Found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m avg_rating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(movie_avg_rating\u001b[38;5;241m.\u001b[39mget(movie_id, np\u001b[38;5;241m.\u001b[39mnan))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get directors & actors for this movie via IMDB scraping\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m directors, actors \u001b[38;5;241m=\u001b[39m \u001b[43mget_directors_actors_for_movie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovie_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimdb_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m actors:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# If no actors found, skip\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 86\u001b[0m, in \u001b[0;36mget_directors_actors_for_movie\u001b[1;34m(movie_id, imdb_id, use_cache)\u001b[0m\n\u001b[0;32m     84\u001b[0m tt_id \u001b[38;5;241m=\u001b[39m imdb_id_to_tt(imdb_id)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_imdb_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtt_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     directors, actors \u001b[38;5;241m=\u001b[39m parse_directors_actors_from_html(html)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m, in \u001b[0;36mfetch_imdb_html\u001b[1;34m(tt_id, delay)\u001b[0m\n\u001b[0;32m     16\u001b[0m req \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m     17\u001b[0m     url,\n\u001b[0;32m     18\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     }\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(req) \u001b[38;5;28;01mas\u001b[39;00m resp:\n\u001b[1;32m---> 28\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(delay)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "File \u001b[1;32mc:\\Users\\Alexa\\miniconda3\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[1;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alexa\\miniconda3\\Lib\\http\\client.py:595\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    593\u001b[0m value \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_left:\n\u001b[0;32m    597\u001b[0m             value\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(amt))\n",
      "File \u001b[1;32mc:\\Users\\Alexa\\miniconda3\\Lib\\http\\client.py:579\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alexa\\miniconda3\\Lib\\http\\client.py:539\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alexa\\miniconda3\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alexa\\miniconda3\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Alexa\\miniconda3\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Merge movies and links to get imdbId + title together\n",
    "movies_links = movies.merge(links, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "# ⚠️ Limit for testing to avoid hammering IMDB\n",
    "# Remove .head(N) to go bigger later (but be careful)\n",
    "N_MOVIES = 86537   # e.g. first 200 movies; adjust as you dare\n",
    "subset = movies_links.head(N_MOVIES)\n",
    "\n",
    "G = nx.MultiGraph()   # actors as nodes, movies as edges\n",
    "\n",
    "for _, row in subset.iterrows():\n",
    "    movie_id = int(row[\"movieId\"])\n",
    "    title = row[\"title\"]\n",
    "    imdb_id = row[\"imdbId\"]\n",
    "\n",
    "    if pd.isna(imdb_id):\n",
    "        continue\n",
    "\n",
    "    avg_rating = float(movie_avg_rating.get(movie_id, np.nan))\n",
    "\n",
    "    # Get directors & actors for this movie via IMDB scraping\n",
    "    directors, actors = get_directors_actors_for_movie(movie_id, imdb_id, use_cache=True)\n",
    "\n",
    "    if not actors:\n",
    "        # If no actors found, skip\n",
    "        continue\n",
    "\n",
    "    # Add actor nodes\n",
    "    for actor in actors:\n",
    "        if actor not in G:\n",
    "            G.add_node(actor, node_type=\"actor\", name=actor)\n",
    "\n",
    "    # For each unordered pair of actors, add an edge representing this movie\n",
    "    for i in range(len(actors)):\n",
    "        for j in range(i + 1, len(actors)):\n",
    "            a1 = actors[i]\n",
    "            a2 = actors[j]\n",
    "            G.add_edge(\n",
    "                a1,\n",
    "                a2,\n",
    "                movieId=movie_id,\n",
    "                title=title,\n",
    "                avg_rating=avg_rating,\n",
    "                directors=directors\n",
    "            )\n",
    "\n",
    "print(\"Graph built.\")\n",
    "print(\"Number of actor nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges (movie-based):\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e32d305",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Example: plot top 10\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m plot_top_k_actors(\u001b[43mG\u001b[49m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_top_k_actors(G, k=10, figsize=(10, 8)):\n",
    "    # All nodes are actors in this graph, but we'll still be explicit\n",
    "    actor_degrees = [(n, G.degree(n)) for n in G.nodes()]\n",
    "    actor_degrees_sorted = sorted(actor_degrees, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_actors = [n for n, deg in actor_degrees_sorted[:k]]\n",
    "\n",
    "    # Get all neighbors of the top actors\n",
    "    neighbors = set()\n",
    "    for a in top_actors:\n",
    "        neighbors.update(G.neighbors(a))\n",
    "\n",
    "    # Induced subgraph on top actors + neighbors\n",
    "    sub_nodes = set(top_actors) | neighbors\n",
    "    H = G.subgraph(sub_nodes).copy()\n",
    "\n",
    "    # Layout\n",
    "    plt.figure(figsize=figsize)\n",
    "    pos = nx.spring_layout(H, seed=42)\n",
    "\n",
    "    # Node sizes: bigger for top actors\n",
    "    sizes = []\n",
    "    colors = []\n",
    "    for n in H.nodes():\n",
    "        if n in top_actors:\n",
    "            sizes.append(400)\n",
    "            colors.append(\"tab:red\")\n",
    "        else:\n",
    "            sizes.append(150)\n",
    "            colors.append(\"tab:blue\")\n",
    "\n",
    "    # Draw\n",
    "    nx.draw_networkx_nodes(H, pos, node_size=sizes, node_color=colors, alpha=0.8)\n",
    "    nx.draw_networkx_edges(H, pos, alpha=0.4)\n",
    "    # Label only top actors (to avoid total clutter)\n",
    "    labels = {n: n for n in top_actors}\n",
    "    nx.draw_networkx_labels(H, pos, labels=labels, font_size=9)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Top {k} actors by degree and their connections\")\n",
    "    plt.show()\n",
    "\n",
    "# Example: plot top 10\n",
    "plot_top_k_actors(G, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68170045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges between Tom Hanks and Tim Allen:\n",
      "  - Movie: Toy Story (1995), avg rating: 3.8935076093890357, directors: ['John Lasseter']\n"
     ]
    }
   ],
   "source": [
    "actor_a = \"Tom Hanks\"\n",
    "actor_b = \"Tim Allen\"\n",
    "\n",
    "if G.has_edge(actor_a, actor_b):\n",
    "    print(f\"Edges between {actor_a} and {actor_b}:\")\n",
    "    for key, data in G[actor_a][actor_b].items():\n",
    "        print(f\"  - Movie: {data['title']}, avg rating: {data['avg_rating']}, directors: {data['directors']}\")\n",
    "else:\n",
    "    print(\"No edge between them in this subset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e64e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== BASIC SIZE METRICS =====\n",
      "Number of nodes (actors): 2,597\n",
      "Number of edges (actor–actor pairs, ignoring multi-edges): 5,509\n",
      "Number of edges in original MultiGraph (with movie multiplicity): 5,532\n",
      "\n",
      "===== DEGREE METRICS =====\n",
      "Average degree: 4.243\n",
      "Max degree: 25\n",
      "\n",
      "===== TOP 20 ACTORS BY DEGREE =====\n",
      "  Cary Grant                     deg = 25\n",
      "  Gene Hackman                   deg = 24\n",
      "  Harvey Keitel                  deg = 21\n",
      "  Robert Duvall                  deg = 21\n",
      "  Sam Neill                      deg = 21\n",
      "  Audrey Hepburn                 deg = 21\n",
      "  Chazz Palminteri               deg = 20\n",
      "  Hugh Grant                     deg = 20\n",
      "  Robin Williams                 deg = 18\n",
      "  Val Kilmer                     deg = 18\n",
      "  Anthony Hopkins                deg = 18\n",
      "  Jim Carrey                     deg = 18\n",
      "  Sylvester Stallone             deg = 18\n",
      "  Antonio Banderas               deg = 18\n",
      "  Christian Slater               deg = 18\n",
      "  Halle Berry                    deg = 18\n",
      "  Tommy Lee Jones                deg = 18\n",
      "  Whoopi Goldberg                deg = 18\n",
      "  Kevin Costner                  deg = 18\n",
      "  Sharon Stone                   deg = 17\n",
      "\n",
      "===== CONNECTED COMPONENTS =====\n",
      "Number of connected components: 223\n",
      "Size of giant component: 1,695 nodes, 4,170 edges\n",
      "Fraction of nodes in giant component: 0.65\n",
      "\n",
      "===== CLUSTERING =====\n",
      "Average clustering coefficient: 0.8144\n",
      "\n",
      "===== ASSORTATIVITY =====\n",
      "Degree assortativity: 0.2399\n",
      "\n",
      "===== SHORTEST PATH METRICS (Giant Component) =====\n",
      "Average shortest path length: 5.899\n",
      "\n",
      "===== CENTRALITY MEASURES =====\n",
      "Computing betweenness centrality on the giant component...\n",
      "\n",
      "Top 20 by betweenness centrality:\n",
      "  Audrey Hepburn                 BC = 0.114280\n",
      "  Cary Grant                     BC = 0.082354\n",
      "  James Coburn                   BC = 0.079860\n",
      "  Walter Matthau                 BC = 0.073955\n",
      "  Gene Hackman                   BC = 0.062359\n",
      "  Hugh Grant                     BC = 0.049616\n",
      "  James Caan                     BC = 0.047931\n",
      "  Arnold Schwarzenegger          BC = 0.043975\n",
      "  Julia Roberts                  BC = 0.037848\n",
      "  Ralph Bellamy                  BC = 0.035620\n",
      "  Val Kilmer                     BC = 0.034884\n",
      "  Fred Astaire                   BC = 0.034255\n",
      "  Jack Lemmon                    BC = 0.032395\n",
      "  Frank Langella                 BC = 0.032152\n",
      "  Halle Berry                    BC = 0.031673\n",
      "  John Leguizamo                 BC = 0.030200\n",
      "  Sharon Stone                   BC = 0.029670\n",
      "  Harvey Keitel                  BC = 0.029304\n",
      "  Robert Duvall                  BC = 0.028284\n",
      "  Laurence Fishburne             BC = 0.028232\n",
      "\n",
      "===== DEGREE CENTRALITY =====\n",
      "  Cary Grant                     DC = 0.009630\n",
      "  Gene Hackman                   DC = 0.009245\n",
      "  Harvey Keitel                  DC = 0.008089\n",
      "  Robert Duvall                  DC = 0.008089\n",
      "  Sam Neill                      DC = 0.008089\n",
      "  Audrey Hepburn                 DC = 0.008089\n",
      "  Chazz Palminteri               DC = 0.007704\n",
      "  Hugh Grant                     DC = 0.007704\n",
      "  Robin Williams                 DC = 0.006934\n",
      "  Val Kilmer                     DC = 0.006934\n",
      "  Anthony Hopkins                DC = 0.006934\n",
      "  Jim Carrey                     DC = 0.006934\n",
      "  Sylvester Stallone             DC = 0.006934\n",
      "  Antonio Banderas               DC = 0.006934\n",
      "  Christian Slater               DC = 0.006934\n",
      "  Halle Berry                    DC = 0.006934\n",
      "  Tommy Lee Jones                DC = 0.006934\n",
      "  Whoopi Goldberg                DC = 0.006934\n",
      "  Kevin Costner                  DC = 0.006934\n",
      "  Sharon Stone                   DC = 0.006549\n",
      "\n",
      "===== DONE =====\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def analyze_actor_network(G_multi, top_k=20):\n",
    "    \"\"\"\n",
    "    G_multi: your MultiGraph with actors as nodes and movie-edges.\n",
    "    We'll create a simple Graph G_simple for metrics that don't support MultiGraph.\n",
    "    \"\"\"\n",
    "    # Simple projection: multiple edges between same actors collapsed into one\n",
    "    G = nx.Graph(G_multi)\n",
    "\n",
    "    print(\"===== BASIC SIZE METRICS =====\")\n",
    "    print(f\"Number of nodes (actors): {G.number_of_nodes():,}\")\n",
    "    print(f\"Number of edges (actor–actor pairs, ignoring multi-edges): {G.number_of_edges():,}\")\n",
    "    print(f\"Number of edges in original MultiGraph (with movie multiplicity): {G_multi.number_of_edges():,}\")\n",
    "    \n",
    "    # Degree sequence\n",
    "    degrees = [deg for _, deg in G.degree()]\n",
    "    avg_degree = np.mean(degrees)\n",
    "    max_degree = np.max(degrees)\n",
    "    print(\"\\n===== DEGREE METRICS =====\")\n",
    "    print(f\"Average degree: {avg_degree:.3f}\")\n",
    "    print(f\"Max degree: {max_degree}\")\n",
    "    \n",
    "    # Top-k actors by degree\n",
    "    print(f\"\\n===== TOP {top_k} ACTORS BY DEGREE =====\")\n",
    "    top_nodes = sorted(G.degree(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    for name, deg in top_nodes:\n",
    "        print(f\"  {name:30s} deg = {deg}\")\n",
    "    \n",
    "    # Connected components on simple graph\n",
    "    print(\"\\n===== CONNECTED COMPONENTS =====\")\n",
    "    comps = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "    giant = G.subgraph(comps[0]).copy()\n",
    "    print(f\"Number of connected components: {len(comps)}\")\n",
    "    print(f\"Size of giant component: {giant.number_of_nodes():,} nodes, {giant.number_of_edges():,} edges\")\n",
    "    print(f\"Fraction of nodes in giant component: {giant.number_of_nodes()/G.number_of_nodes():.2f}\")\n",
    "    \n",
    "    # Average clustering coefficient (needs simple graph)\n",
    "    print(\"\\n===== CLUSTERING =====\")\n",
    "    avg_clustering = nx.average_clustering(G)\n",
    "    print(f\"Average clustering coefficient: {avg_clustering:.4f}\")\n",
    "    \n",
    "    # Degree assortativity (simple graph)\n",
    "    print(\"\\n===== ASSORTATIVITY =====\")\n",
    "    assort = nx.degree_assortativity_coefficient(G)\n",
    "    print(f\"Degree assortativity: {assort:.4f}\")\n",
    "    \n",
    "    # Shortest-path metrics (giant component only)\n",
    "    print(\"\\n===== SHORTEST PATH METRICS (Giant Component) =====\")\n",
    "    try:\n",
    "        apl = nx.average_shortest_path_length(giant)\n",
    "        print(f\"Average shortest path length: {apl:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not compute exact average shortest path length:\", e)\n",
    "        print(\"Consider approximations or sampling nodes instead.\")\n",
    "    \n",
    "    # Betweenness centrality on giant component\n",
    "    print(\"\\n===== CENTRALITY MEASURES =====\")\n",
    "    print(\"Computing betweenness centrality on the giant component...\")\n",
    "    if giant.number_of_nodes() > 5000:\n",
    "        print(\"WARNING: Graph is large. Using k=500 approximation for speed.\")\n",
    "        bc = nx.betweenness_centrality(giant, k=500, seed=42)\n",
    "    else:\n",
    "        bc = nx.betweenness_centrality(giant)\n",
    "    \n",
    "    top_bc = sorted(bc.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    print(f\"\\nTop {top_k} by betweenness centrality:\")\n",
    "    for node, score in top_bc:\n",
    "        print(f\"  {node:30s} BC = {score:.6f}\")\n",
    "    \n",
    "    # Degree centrality (on simple graph)\n",
    "    print(\"\\n===== DEGREE CENTRALITY =====\")\n",
    "    dc = nx.degree_centrality(G)\n",
    "    top_dc = sorted(dc.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    for node, score in top_dc:\n",
    "        print(f\"  {node:30s} DC = {score:.6f}\")\n",
    "    \n",
    "    print(\"\\n===== DONE =====\")\n",
    "\n",
    "\n",
    "# Run it on your MultiGraph G\n",
    "analyze_actor_network(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2bc6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
